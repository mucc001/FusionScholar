{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2f7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import openai\n",
    "from urllib.request import urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89c12f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('df1_for_GPT3_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e3953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyPhrases</th>\n",
       "      <th>paperAbstract</th>\n",
       "      <th>numKeyReferences</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>numCitedBy</th>\n",
       "      <th>numKeyCitations</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Isomorphism', 'Duality', 'DUAL', 'Undirected...</td>\n",
       "      <td>[\"We provide a correspondence between the subj...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Duality Theorems for Finite Structures (Char...</td>\n",
       "      <td>['JCT']</td>\n",
       "      <td>[54]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>6e4eddf4d6671c37537bb5d1c9623353b62e8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Person Reidentification', 'China Email', 'Si...</td>\n",
       "      <td>['—This paper proposes a novel approach to per...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>['Deep Ranking for Person Re-identification vi...</td>\n",
       "      <td>['TIP']</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>8d8afef13a8f6195d3b874231e5e767cf62f3c50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Natural Language Text', 'PML', 'C.F.', 'Auto...</td>\n",
       "      <td>['We present a system for identifying the sema...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Automatic Labeling of Semantic Roles']</td>\n",
       "      <td>['COLING']</td>\n",
       "      <td>[684]</td>\n",
       "      <td>[63]</td>\n",
       "      <td>04a8d271bc4384dbfbb417bfb625feb01cb44666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Motion SFM', 'Landmarkbased Approaches', 'Gr...</td>\n",
       "      <td>['Ego-motion estimation for an agile single ca...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Real-Time Simultaneous Localisation and Mapp...</td>\n",
       "      <td>['ICCV']</td>\n",
       "      <td>[483]</td>\n",
       "      <td>[35]</td>\n",
       "      <td>102e50c2c9a8e3d00de64a26759916c926fa3db6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Semantic Pattern', 'Positive Sentiment', 'Se...</td>\n",
       "      <td>['Sentiment analysis over Twitter offer organi...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Semantic Sentiment Analysis of Twitter']</td>\n",
       "      <td>['SEMWEB']</td>\n",
       "      <td>[57]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>ec4a94637ecd115219869e9df8902cb7282481e0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          keyPhrases  \\\n",
       "0  ['Isomorphism', 'Duality', 'DUAL', 'Undirected...   \n",
       "1  ['Person Reidentification', 'China Email', 'Si...   \n",
       "2  ['Natural Language Text', 'PML', 'C.F.', 'Auto...   \n",
       "3  ['Motion SFM', 'Landmarkbased Approaches', 'Gr...   \n",
       "4  ['Semantic Pattern', 'Positive Sentiment', 'Se...   \n",
       "\n",
       "                                       paperAbstract numKeyReferences  \\\n",
       "0  [\"We provide a correspondence between the subj...              [1]   \n",
       "1  ['—This paper proposes a novel approach to per...              [4]   \n",
       "2  ['We present a system for identifying the sema...              [1]   \n",
       "3  ['Ego-motion estimation for an agile single ca...              [1]   \n",
       "4  ['Sentiment analysis over Twitter offer organi...              [0]   \n",
       "\n",
       "                                               title       venue numCitedBy  \\\n",
       "0  ['Duality Theorems for Finite Structures (Char...     ['JCT']       [54]   \n",
       "1  ['Deep Ranking for Person Re-identification vi...     ['TIP']        [6]   \n",
       "2           ['Automatic Labeling of Semantic Roles']  ['COLING']      [684]   \n",
       "3  ['Real-Time Simultaneous Localisation and Mapp...    ['ICCV']      [483]   \n",
       "4         ['Semantic Sentiment Analysis of Twitter']  ['SEMWEB']       [57]   \n",
       "\n",
       "  numKeyCitations                                     docno  \n",
       "0             [4]  6e4eddf4d6671c37537bb5d1c9623353b62e8531  \n",
       "1             [0]  8d8afef13a8f6195d3b874231e5e767cf62f3c50  \n",
       "2            [63]  04a8d271bc4384dbfbb417bfb625feb01cb44666  \n",
       "3            [35]  102e50c2c9a8e3d00de64a26759916c926fa3db6  \n",
       "4             [1]  ec4a94637ecd115219869e9df8902cb7282481e0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093be2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660a3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4afabc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = np.load(\"title_ab_embeddings_gpt3.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4fff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['doc_emb'] = doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98698b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    top100 = search_100(query)\n",
    "    result = rerank(df1, query, 10, top100)\n",
    "    dict_list = []\n",
    "    for index, row in result.iterrows():\n",
    "        temp = {}\n",
    "        temp['title'] = row['title']\n",
    "        temp['paperAbstract'] = row['paperAbstract']\n",
    "        temp['venue'] = row['venue']\n",
    "        temp['numCitedBy'] = row['numCitedBy']\n",
    "        dict_list.append(temp)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d776e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_100(query):\n",
    "    MAX_SIZE = 100\n",
    "    payload = {\n",
    "        \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": ['paperAbstract','title']\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    resp = es.search(index=\"s2_doc\", query=payload, size=MAX_SIZE)\n",
    "    result = []\n",
    "    # Extract info needed for display. \n",
    "    for item in resp['hits']['hits']:\n",
    "        result.append(item['_id'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c64e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, query, n, top100):\n",
    "    mask = df['docno'].isin(top100)\n",
    "    selected_rows = df.loc[mask]\n",
    "    column_name = \"similarity\"\n",
    "    query = openai.Embedding.create(\n",
    "    input=query,\n",
    "    engine=\"text-search-davinci-query-001\"\n",
    ")[\"data\"][0][\"embedding\"]\n",
    "    selected_rows[column_name] = selected_rows['doc_emb'].apply(lambda x: cosine_similarity(x[\"data\"][0][\"embedding\"], query))\n",
    "    result = (\n",
    "        selected_rows.sort_values(column_name, ascending=False)\n",
    "        .head(n)\n",
    "    )\n",
    "    result = result.drop(columns = ['docno', 'doc_emb'])\n",
    "#     result = pd.DataFrame.to_json(result, orient='index')\n",
    "#     result = json.loads(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acc0bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/xx88m0sx4s96c12lqts9h7tm0000gn/T/ipykernel_92328/3578028534.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows[column_name] = selected_rows['doc_emb'].apply(lambda x: cosine_similarity(x[\"data\"][0][\"embedding\"], query))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.384714126586914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyPhrases</th>\n",
       "      <th>paperAbstract</th>\n",
       "      <th>numKeyReferences</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>numCitedBy</th>\n",
       "      <th>numKeyCitations</th>\n",
       "      <th>docno</th>\n",
       "      <th>doc_emb</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>['Translation Language Model', 'Formule', 'Voc...</td>\n",
       "      <td>['We propose a new probabilistic approach to i...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Information Retrieval as Statistical Transla...</td>\n",
       "      <td>['SIGIR']</td>\n",
       "      <td>[294]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>15281680463698dca403697bd627af4efebc98a2</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.403286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6324</th>\n",
       "      <td>['TREC', 'Statistical Significance', 'Average ...</td>\n",
       "      <td>['The effectiveness of information retrieval s...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['Information retrieval system evaluation: eff...</td>\n",
       "      <td>['SIGIR']</td>\n",
       "      <td>[166]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>4314bbc2a62c37a9b66d759fc35ae6f7607344e0</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.397071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>['Agglomerative Hierarchical Clustering', 'Que...</td>\n",
       "      <td>['1 Boolean retrieval 1 2 The term vocabulary ...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Introduction to information retrieval']</td>\n",
       "      <td>['DAGLIB']</td>\n",
       "      <td>[2835]</td>\n",
       "      <td>[173]</td>\n",
       "      <td>040678daf6a49a88345ee0c680fccfd134f24d4b</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.393794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>['Complex Number', 'Conditional Logic', 'Quant...</td>\n",
       "      <td>['Information retrieval, IR, the science of ex...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['The geometry of information retrieval']</td>\n",
       "      <td>['DAGLIB']</td>\n",
       "      <td>[108]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>f43f289efeadfe63c553876eeec71f97f5d8c1a5</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.391709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>['Language Model', 'IR Model', 'Query Term', '...</td>\n",
       "      <td>['Empirical studies of information retrieval m...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['A formal study of information retrieval heur...</td>\n",
       "      <td>['SIGIR']</td>\n",
       "      <td>[119]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>2c68c7faa89b104b78e2850dbade5a81f0743874</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.387235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Information Retrieval - Algorithms and Heuri...</td>\n",
       "      <td>['IRS']</td>\n",
       "      <td>[162]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>b1a660f7dec8ec270f52cf0bf2dc8ef98ae1dd11</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.386882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>['WWW', 'ENT', 'Engine', 'Information Retrieva...</td>\n",
       "      <td>['In this paper we review studies of the growt...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>['Information retrieval on the web']</td>\n",
       "      <td>['CSUR']</td>\n",
       "      <td>[130]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>20987764a34a506a3235446a75aeea0d4dc1b4e8</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.386806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Information retrieval for music and motion']</td>\n",
       "      <td>['DAGLIB']</td>\n",
       "      <td>[226]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>b9bcc3bdb022b47f7541acaa09c8d9ca0ae27a16</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.386644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Introduction to Modern Information Retrieval']</td>\n",
       "      <td>['MG']</td>\n",
       "      <td>[3472]</td>\n",
       "      <td>[153]</td>\n",
       "      <td>3bb73407096cbb0f5d884eb108d694b43580004b</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.381862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>['Average Precision', 'B Ttcher', 'Inverted In...</td>\n",
       "      <td>['']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['Information Retrieval - Implementing and Eva...</td>\n",
       "      <td>['DAGLIB']</td>\n",
       "      <td>[104]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0a717685158723040c56b42d67fc8988fab9fc73</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>0.381144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keyPhrases  \\\n",
       "5577  ['Translation Language Model', 'Formule', 'Voc...   \n",
       "6324  ['TREC', 'Statistical Significance', 'Average ...   \n",
       "3615  ['Agglomerative Hierarchical Clustering', 'Que...   \n",
       "1406  ['Complex Number', 'Conditional Logic', 'Quant...   \n",
       "7695  ['Language Model', 'IR Model', 'Query Term', '...   \n",
       "5567                                                NaN   \n",
       "446   ['WWW', 'ENT', 'Engine', 'Information Retrieva...   \n",
       "7880                                                NaN   \n",
       "160                                                 NaN   \n",
       "1895  ['Average Precision', 'B Ttcher', 'Inverted In...   \n",
       "\n",
       "                                          paperAbstract numKeyReferences  \\\n",
       "5577  ['We propose a new probabilistic approach to i...              [0]   \n",
       "6324  ['The effectiveness of information retrieval s...              [3]   \n",
       "3615  ['1 Boolean retrieval 1 2 The term vocabulary ...              [0]   \n",
       "1406  ['Information retrieval, IR, the science of ex...              [0]   \n",
       "7695  ['Empirical studies of information retrieval m...              [0]   \n",
       "5567                                               ['']              [0]   \n",
       "446   ['In this paper we review studies of the growt...              [5]   \n",
       "7880                                               ['']              [0]   \n",
       "160                                                ['']              [0]   \n",
       "1895                                               ['']              [0]   \n",
       "\n",
       "                                                  title       venue  \\\n",
       "5577  ['Information Retrieval as Statistical Transla...   ['SIGIR']   \n",
       "6324  ['Information retrieval system evaluation: eff...   ['SIGIR']   \n",
       "3615          ['Introduction to information retrieval']  ['DAGLIB']   \n",
       "1406          ['The geometry of information retrieval']  ['DAGLIB']   \n",
       "7695  ['A formal study of information retrieval heur...   ['SIGIR']   \n",
       "5567  ['Information Retrieval - Algorithms and Heuri...     ['IRS']   \n",
       "446                ['Information retrieval on the web']    ['CSUR']   \n",
       "7880     ['Information retrieval for music and motion']  ['DAGLIB']   \n",
       "160    ['Introduction to Modern Information Retrieval']      ['MG']   \n",
       "1895  ['Information Retrieval - Implementing and Eva...  ['DAGLIB']   \n",
       "\n",
       "     numCitedBy numKeyCitations                                     docno  \\\n",
       "5577      [294]            [26]  15281680463698dca403697bd627af4efebc98a2   \n",
       "6324      [166]             [6]  4314bbc2a62c37a9b66d759fc35ae6f7607344e0   \n",
       "3615     [2835]           [173]  040678daf6a49a88345ee0c680fccfd134f24d4b   \n",
       "1406      [108]             [4]  f43f289efeadfe63c553876eeec71f97f5d8c1a5   \n",
       "7695      [119]             [6]  2c68c7faa89b104b78e2850dbade5a81f0743874   \n",
       "5567      [162]             [3]  b1a660f7dec8ec270f52cf0bf2dc8ef98ae1dd11   \n",
       "446       [130]             [6]  20987764a34a506a3235446a75aeea0d4dc1b4e8   \n",
       "7880      [226]            [17]  b9bcc3bdb022b47f7541acaa09c8d9ca0ae27a16   \n",
       "160      [3472]           [153]  3bb73407096cbb0f5d884eb108d694b43580004b   \n",
       "1895      [104]             [1]  0a717685158723040c56b42d67fc8988fab9fc73   \n",
       "\n",
       "                                                doc_emb  similarity  \n",
       "5577  {'object': 'list', 'data': [{'object': 'embedd...    0.403286  \n",
       "6324  {'object': 'list', 'data': [{'object': 'embedd...    0.397071  \n",
       "3615  {'object': 'list', 'data': [{'object': 'embedd...    0.393794  \n",
       "1406  {'object': 'list', 'data': [{'object': 'embedd...    0.391709  \n",
       "7695  {'object': 'list', 'data': [{'object': 'embedd...    0.387235  \n",
       "5567  {'object': 'list', 'data': [{'object': 'embedd...    0.386882  \n",
       "446   {'object': 'list', 'data': [{'object': 'embedd...    0.386806  \n",
       "7880  {'object': 'list', 'data': [{'object': 'embedd...    0.386644  \n",
       "160   {'object': 'list', 'data': [{'object': 'embedd...    0.381862  \n",
       "1895  {'object': 'list', 'data': [{'object': 'embedd...    0.381144  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "result = search(\"information retrieval\")\n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print(diff)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50a15205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/xx88m0sx4s96c12lqts9h7tm0000gn/T/ipykernel_92328/886092020.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_rows[column_name] = selected_rows['doc_emb'].apply(lambda x: cosine_similarity(x[\"data\"][0][\"embedding\"], query))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': \"['Deep learning.']\",\n",
       "  'paperAbstract': \"['Overview of the tutorial • A brief history of deep learning. • How to learn multi-layer generative models of unlabelled data by learning one layer of features at a time. – What is really going on when we stack RBMs to form a deep belief net. • How to use generative models to make discriminative training methods work much better for classification and regression. • How to modify RBMs to deal with real-valued input.']\",\n",
       "  'venue': \"['Nature']\",\n",
       "  'numCitedBy': '[254]'},\n",
       " {'title': \"['Deep Learning of Representations for Unsupervised and Transfer Learning']\",\n",
       "  'paperAbstract': \"['Deep learning algorithms seek to exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. The objective is to make these higher-level representations more abstract, with their individual features more invariant to most of the variations that are typically present in the training distribution, while collectively preserving as much as possible of the information in the input. Ideally, we would like these representations to disentangle the unknown factors of variation that underlie the training distribution. Such unsupervised learning of representations can be exploited usefully under the hypothesis that the input distribution P (x) is structurally related to some task of interest, say predicting P (y|x). This paper focusses on why unsupervised pre-training of representations can be useful, and how it can be exploited in the transfer learning scenario, where we care about predictions on examples that are not from the same distribution as the training distribution.']\",\n",
       "  'venue': \"['JMLR']\",\n",
       "  'numCitedBy': '[58]'},\n",
       " {'title': \"['Multimodal Deep Learning']\",\n",
       "  'paperAbstract': \"['Deep networks have been successfully applied to unsupervised feature learning for single modalities (e.g., text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (e.g., video) can be learned if multiple modalities (e.g., audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evaluate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our models are validated on the CUAVE and AVLet-ters datasets on audiovisual speech classification , demonstrating best published visual speech classification on AVLetters and effective shared representation learning.']\",\n",
       "  'venue': \"['ICML']\",\n",
       "  'numCitedBy': '[226]'},\n",
       " {'title': \"['Deep learning via semi-supervised embedding']\",\n",
       "  'paperAbstract': \"['We show how nonlinear embedding algorithms popular for use with <i>shallow</i> semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to <i>deep</i> learning whilst yielding competitive error rates compared to those methods, and existing <i>shallow</i> semi-supervised techniques.']\",\n",
       "  'venue': \"['ICML']\",\n",
       "  'numCitedBy': '[162]'},\n",
       " {'title': \"['Deep learning in speech synthesis']\",\n",
       "  'paperAbstract': \"['']\",\n",
       "  'venue': \"['SSW']\",\n",
       "  'numCitedBy': '[5]'},\n",
       " {'title': \"['Deep Learning in Neural Networks: An Overview']\",\n",
       "  'paperAbstract': '[\\'In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks. Preface This is the preprint of an invited Deep Learning (DL) overview. One of its goals is to assign credit to those who contributed to the present state of the art. I acknowledge the limitations of attempting to achieve this goal. The DL research community itself may be viewed as a continually evolving, deep network of scientists who have influenced each other in complex ways. Starting from recent DL results, I tried to trace back the origins of relevant ideas through the past half century and beyond, sometimes using \" local search \" to follow citations of citations backwards in time. Since not all DL publications properly acknowledge earlier relevant work, additional global search strategies were employed , aided by consulting numerous neural network experts. As a result, the present preprint mostly consists of references. Nevertheless, through an expert selection bias I may have missed important work. A related bias was surely introduced by my special familiarity with the work of my own DL research group in the past quarter-century. For these reasons, this work should be viewed as merely a snapshot of an ongoing credit assignment process. To help improve it, please do not hesitate to send corrections and suggestions to juergen@idsia.ch.\\']',\n",
       "  'venue': \"['NN']\",\n",
       "  'numCitedBy': '[178]'},\n",
       " {'title': \"['Deep Learning of Representations: Looking Forward']\",\n",
       "  'paperAbstract': '[\\'Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical results, learning algorithms and breakthrough experiments, several challenges lie ahead. This paper proposes to examine some of these challenges, centering on the questions of scaling deep learning algorithms to much larger models and datasets, reducing optimization difficulties due to ill-conditioning or local minima, designing more efficient and powerful inference and sampling procedures, and learning to disentangle the factors of variation underlying the observed data. It also proposes a few forward-looking research directions aimed at overcoming these challenges. Deep learning is an emerging approach within the machine learning research community. Deep learning algorithms have been proposed in recent years to move machine learning systems towards the discovery of multiple levels of representation. They have had important empirical successes in a number of traditional AI applications such as computer vision and natural language processing. See (Bengio, 2009; Bengio et al., 2013d) for reviews and Bengio (2013c) and the other chapters of the book by Montavon and Muller (2012) for practical guidelines. Deep learning is attracting much attention both from the academic and industrial communities. Companies like Google, Microsoft, Apple, IBM and Baidu are investing in deep learning, with the first widely distributed products being used by consumers aimed at speech recognition. Deep learning is also used for object recognition (Google Goggles), image and music information retrieval (Google Image Search, Google Music), as well as computational advertising (Corrado, 2012). A deep learning building block (the restricted Boltzmann machine, or RBM) was used as a crucial part of the winning entry of a million-dollar machine learning competition (the Netflix competition) (Salakhutdinov et al., 2007; Töscher et al., 2009). The New York Times covered the subject twice in 2012, with front-page articles. 1 Another series of articles (including a third New York Times article) covered a more recent event showing off the application of deep learning in a major Kaggle competition for drug discovery (for example see \" Deep Learning-The Biggest Data Science Breakthrough of the Decade \" 2. Much more recently, Google bought out (\" acqui-hired \") a company (DNNresearch) created by University of Toronto professor Geoffrey Hinton (the founder and leading researcher of deep learning) and two of his PhD students, Ilya Sutskever and Alex Krizhevsky, with the press …\\']',\n",
       "  'venue': \"['SLSP']\",\n",
       "  'numCitedBy': '[51]'},\n",
       " {'title': \"['Deep Learning for Efficient Discriminative Parsing']\",\n",
       "  'paperAbstract': '[\\'We propose a new fast purely discrimina-tive algorithm for natural language parsing, based on a \" deep \" recurrent convolutional graph transformer network (GTN). Assuming a decomposition of a parse tree into a stack of \" levels \" , the network predicts a level of the tree taking into account predictions of previous levels. Using only few basic text features which leverage word representations from Collobert and Weston (2008), we show similar performance (in F 1 score) to existing pure discriminative parsers and existing \" benchmark \" parsers (like Collins parser, probabilistic context-free grammars based), with a huge speed advantage.\\']',\n",
       "  'venue': \"['JMLR']\",\n",
       "  'numCitedBy': '[63]'},\n",
       " {'title': \"['Continuous Learning of Human Activity Models Using Deep Nets']\",\n",
       "  'paperAbstract': \"['Learning activity models continuously from streaming videos is an immensely important problem in video surveillance, video indexing , etc. Most of the research on human activity recognition has mainly focused on learning a static model considering that all the training instances are labeled and present in advance, while in streaming videos new instances continuously arrive and are not labeled. In this work, we propose a continuous human activity learning framework from streaming videos by intricately tying together deep networks and active learning. This allows us to automatically select the most suitable features and to take the advantage of incoming unlabeled instances to improve the existing model incrementally. Given the segmented activities from streaming videos, we learn features in an unsupervised manner using deep networks and use active learning to reduce the amount of manual labeling of classes. We conduct rigorous experiments on four challenging human activity datasets to demonstrate the effectiveness of our framework for learning human activity models continuously.']\",\n",
       "  'venue': \"['ECCV']\",\n",
       "  'numCitedBy': '[8]'},\n",
       " {'title': \"['Deep Learning using Linear Support Vector Machines']\",\n",
       "  'paperAbstract': '[\\'Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing , and bioinformatics. For classification tasks, most of these \" deep learning \" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the soft-max layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neu-ral nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop\\\\\\'s face expression recognition challenge.\\']',\n",
       "  'venue': \"['']\",\n",
       "  'numCitedBy': '[38]'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search(\"deep learning\")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
